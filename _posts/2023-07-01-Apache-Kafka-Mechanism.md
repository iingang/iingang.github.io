---
title: "[Kafka] Apache Kafka 구성요소 및 동작방식"
date: 2023-07-01 14:00:00 +0900
categories: [Messaging System,Apache Kafka]
tags: [Kafka, Message queue, Messaging System, Components]
typora-root-url: ./
---


# **Apache Kafka Components 소개**

---

![image-20240617133555711](/../assets/img/posts/2023-07-01-Apache-Kafka-Mechanism/image-20240617133555711.png)



Kafka는 대규모 실시간 데이터 스트리밍 플랫폼으로, 데이터를 생성하고 처리하는 다양한 컴포넌트로 구성됩니다. 이 글에서는 카프카의 주요 구성 요소인 프로듀서, 컨슈머, 토픽, 파티션, 브로커, 주키퍼, 그리고 커넥터에 대해 알아보겠습니다.

<br/>

### **1. 프로듀서와 컨슈머 (Producer & Consumer)** 

Kafka에서 데이터를 생성하고 보내는 역할은 **프로듀서**가, 데이터를 가져와 처리하는 역할은 **컨슈머**가 담당합니다.

- **프로듀서**: 메시지를 만들어 특정 토픽으로 데이터를 보냅니다.
- **컨슈머**: 토픽에서 데이터를 폴링(polling) 방식으로 가져와 처리합니다.

이때 화살표의 방향을 잘 보면 데이터의 흐름을 나타냅니다. 컨슈머는 데이터를 U턴하여 가져오는 방식으로 동작합니다. 이는 실제로 카프카에서 데이터를 보내는 방식이 아니라, 컨슈머에서 데이터를 가져오는 방식을 나타냅니다.

<br/>

### **2. 토픽과 파티션 (Topic & Partition)**

**토픽**은 Kafka에서 데이터가 저장되는 논리적인 개념입니다. 실제 데이터는 토픽 내의 **파티션**에 저장됩니다.

- **토픽**: 논리적인 개념으로, 디렉토리나 파일처럼 눈에 보이지 않습니다.
- **파티션**: 실제 데이터를 저장하는 단위로, 하나의 토픽은 여러 파티션으로 나뉠 수 있습니다.

예를 들어, Topic B와 C처럼 파티션이 여러 개인 경우, 데이터가 분산되어 여러 브로커에서 병렬로 처리될 수 있습니다. 이를 통해 데이터 처리 성능을 향상시킬 수 있습니다.

<br/>

### **3. 브로커와 주키퍼 (Broker & Zookeeper)**

**브로커**는 Kafka의 핵심 컴포넌트로, 프로듀서와 컨슈머 사이에서 데이터 스트림을 안정적으로 관리하는 역할을 합니다. 브로커는 토픽 내의 파티션을 분산 및 유지 관리하며, 데이터를 안정적으로 전달합니다.

**주키퍼**는 서버 간의 정보를 중앙에서 효과적으로 관리하는 코디네이터 역할을 합니다. 주키퍼는 브로커의 상태 정보나 파티션 할당 정보와 같은 메타데이터를 관리하여 Kafka 시스템이 안정적으로 동작할 수 있도록 지원합니다.

<br/>

### **4. 커넥터 (Connector)**

**커넥터**는 외부 시스템과 Kafka 간의 데이터를 효율적으로 전송할 수 있도록 도와주는 컴포넌트입니다. 커넥터는 크게 두 가지로 나뉩니다.

- **Source Connector**: 외부 시스템에서 Kafka로 데이터를 가져옵니다.
- **Sink Connector**: Kafka에서 외부 시스템으로 데이터를 보냅니다.

예를 들어, 특정 DB에서 데이터를 가져와 Kafka에 저장하고 싶다면 JDBC Source Connector를 이용할 수 있습니다. 반대로, Kafka 토픽의 데이터를 다른 DB로 전송하기 위해서는 JDBC Sink Connector를 사용합니다.

커넥터를 사용하면 개발자가 직접 프로듀서와 컨슈머를 개발하지 않아도 되므로, 개발 시간을 절약할 수 있고 외부 시스템 간의 데이터 흐름을 더 효율적으로 관리할 수 있습니다.

<br/>

### **결론**

Kafka는 다양한 컴포넌트들이 유기적으로 작동하여 대규모 실시간 데이터 스트리밍을 처리합니다. 

프로듀서와 컨슈머를 통해 데이터를 주고받고, 토픽과 파티션을 통해 데이터를 분산 저장하며, 브로커와 주키퍼를 통해 시스템의 안정성을 유지합니다. 

마지막으로, 커넥터를 통해 외부 시스템과의 데이터를 효율적으로 전송할 수 있습니다. 

Kafka의 이러한 구성 요소들을 잘 이해하고 활용하면, 대규모 데이터 처리 시스템을 효과적으로 구축할 수 있습니다.
